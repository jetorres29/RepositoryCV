{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Needs the package Pandas to be installed. Check Anaconda Environments and Packages.\n",
    "from sklearn.decomposition import PCA # Needs SciKit Learn package to be installed. Check Anaconda Environments and Packages.4\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces94_male = readFaces94MaleFaces(gray=True)\n",
    "faces94_female = readFaces94FemaleFaces(gray=True)\n",
    "faces94_malestaff = readFaces94MaleStaffFaces(gray=True)\n",
    "\n",
    "dataset = np.vstack((faces94_male, faces94_female, faces94_malestaff))\n",
    "\n",
    "dataset_N, height, width = dataset.shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data centralization and calculate of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all = np.mean(dataset.reshape(dataset_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_all, plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset.reshape(dataset_N, height*width) - np.mean(dataset.reshape(dataset_N, height*width), axis=0)\n",
    "datasetmean=(1/(dataset_N-1))*(np.dot(data,data.T)) # Covariance matrix\n",
    "print(datasetmean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subspaces method: Eigenfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(datasetmean) # u: eigenvectors in columns; s: eigenvalues; vh = eigenvectors in rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face space: selection of subspace components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Investigator's criteria of variability captured (hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_percentage = 0.85 # Selected variability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_eig = np.sum(s)\n",
    "percentage_variance = np.divide(s, sum_eig)\n",
    "sum_var = 0\n",
    "num_var = 0\n",
    "for i in np.arange(percentage_variance.shape[0]):\n",
    "    if sum_var >= representation_percentage:\n",
    "        num_var = i\n",
    "        break;\n",
    "    \n",
    "    sum_var += percentage_variance[i]\n",
    "    \n",
    "num_var_select=num_var    \n",
    "print(\"Principal components number: \",num_var_select)\n",
    "print(\"Percent of variability captured: \",sum_var*100)\n",
    "print(\"Images in datasets\",dataset_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Investigator's criteria of threshold contribution value (hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_per=np.cumsum(percentage_variance)\n",
    "for i in range(1,len(s)):\n",
    "    change=(cum_per[i]-cum_per[i-1])/cum_per[i-1]*100\n",
    "    if(change<.01):\n",
    "        num_var=i-1\n",
    "        print(\"First\",num_var, \"components with \",cum_per[num_var]*100,\"percent of variability captured and from which the contribution is less than 0.01%\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cum_per*100)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Cumulative Summation of the Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EigenvectorsA=np.dot(data.T,u[:,0:num_var_select])\n",
    "NormEigenvectorsA = preprocessing.normalize(EigenvectorsA,axis=0, norm='l2')\n",
    "print(np.linalg.norm(NormEigenvectorsA[:,5],ord=None))#check normalizacion vectores propios de XT.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 4\n",
    "plt.figure(figsize=(30,20))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(NormEigenvectorsA[:,i].reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection of an image on face space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0.8\n",
    "step=0.06\n",
    "stop=1\n",
    "\n",
    "facespace(percentage_variance,dataset,data,mean_all,u,dataset_N,height,width,start,step,stop,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Principal components number: \",num_var_select)\n",
    "print(\"Percent of variability captured: \",sum_var*100)\n",
    "print(\"Images in datasets\",dataset_N)\n",
    "print(\"Omega matrix facespace\",np.dot(data,NormEigenvectorsA).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specific image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "n=widgets.BoundedFloatText(value=2690,min=0,max=dataset_N,description='image:')\n",
    "display(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_image=int(n.value)\n",
    "specificimage(data,dataset,NormEigenvectorsA,mean_all,N_image,dataset_N,height,width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomimage(data,dataset,NormEigenvectorsA,mean_all,dataset_N,height,width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances an outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReconstructed=np.dot(np.dot(data,NormEigenvectorsA),NormEigenvectorsA.T)+mean_all.reshape(height*width)\n",
    "print(dataReconstructed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm=widgets.Dropdown(options=['1', '2', 'inf'],value='2',description='Norm:',disabled=False)\n",
    "display(Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(Norm.value)=='inf':\n",
    "    ordn=np.inf\n",
    "else:\n",
    "    ordn=int(Norm.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edistance = np.linalg.norm(np.subtract(dataReconstructed, dataset.reshape(dataset_N, height*width)), ord=ordn, axis=1)\n",
    "print(edistance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histbox(edistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, outliers, zsort, indexsort, z=outlierseigenfaces(edistance,3)\n",
    "\n",
    "print('Outliers threshold method=',np.size(outliers))\n",
    "print('threshold=',threshold)\n",
    "CVresult={'outliers distance':outliers,'z':zsort}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.sort_values('z', axis = 0, ascending = False, inplace = True, na_position ='first') \n",
    "df.head(np.size(outliers)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### low and high distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Similar Image\")\n",
    "ax1.imshow(dataset[indexsort[0]], plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"Dissimilar Image\")\n",
    "ax2.imshow(dataset[indexsort[-1]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### high distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 2\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"z \"+str(z[indexsort[-(i+1)]]),fontsize=20)\n",
    "    plt.imshow(dataset[indexsort[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscapes = np.array(readLandsCapeImage(gray=True))\n",
    "\n",
    "landimages(landscapes,height,width,mean_all,NormEigenvectorsA,ordn,outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landimage=landscapes.reshape(landscapes.shape[0],height*width)-mean_all.reshape(height*width)\n",
    "dataReconstructedland=np.dot(np.dot(landimage,NormEigenvectorsA),NormEigenvectorsA.T)+mean_all.reshape(height*width)\n",
    "print(dataReconstructedland.shape)\n",
    "\n",
    "edistanceland = np.linalg.norm(np.subtract(dataReconstructedland, landscapes.reshape(landscapes.shape[0], height*width)), ord=ordn, axis=1)\n",
    "totaldistance=np.append(edistance,edistanceland)\n",
    "histbox(totaldistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.ones(dataset_N)\n",
    "y_true=np.append(y_true,np.zeros(landscapes.shape[0]))\n",
    "y_pred=(totaldistance<=outliers[0])*1\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print('TP=', tp,'TN=',tn,'FP=',fp,'FN=', fn)\n",
    "print('accuracy= ', (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Heatmap\")\n",
    "prediction_data = {'y_Actual': y_true,'y_Predicted': y_pred}\n",
    "df = pd.DataFrame(prediction_data, columns=['y_Actual','y_Predicted'])\n",
    "confusionmatrix1 = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "ax=sns.heatmap(confusionmatrix1, annot=True,cmap='Blues', fmt='.0f');\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_land= int(np.where(edistanceland < outliers[0])[0][3])\n",
    "landimage=landscapes[N_land].reshape(height*width)-mean_all.reshape(height*width)#seleccionar imagen individual\n",
    "wland=np.dot(landimage,NormEigenvectorsA)#pesos w de cada Eigenface en subespacio generado\n",
    "Reconstland=np.dot(wland,NormEigenvectorsA.T)+mean_all.reshape(height*width)#es mas claro w*vectores propios transpuestos\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Land image\")\n",
    "ax1.imshow(landscapes[N_land], plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"Reconstructed land Image\")\n",
    "ax2.imshow(Reconstland.reshape(height, width), plt.cm.gray)\n",
    "print('distancia',edistanceland[N_land])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, tncv, fpcv, fncv, tpcv=kfold(y_true,landscapes,dataset,height,width,ordn)\n",
    "CVresult={'accuracy':accuracy,'tn':tncv,'fp':fpcv,'fn':fncv,'tp':tpcv}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscapes = np.array(readLandsCapeImage(gray=True))\n",
    "datasetfull = np.vstack((dataset,landscapes))\n",
    "\n",
    "datasetfull_N, height, width = datasetfull.shape\n",
    "datasetfull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all_full = np.mean(datasetfull.reshape(datasetfull_N, height*width), axis=0).reshape(height, width)\n",
    "plt.imshow(mean_all_full, plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafull=datasetfull.reshape(datasetfull_N, height*width) - np.mean(datasetfull.reshape(datasetfull_N, height*width), axis=0)\n",
    "datasetmeanfull=(1/(datasetfull_N-1))*(np.dot(datafull,datafull.T))\n",
    "print(datasetmeanfull.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(datasetmeanfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_percentage = 0.80\n",
    "\n",
    "sum_eig = np.sum(s)\n",
    "percentage_variance = np.divide(s, sum_eig)\n",
    "sum_var = 0\n",
    "num_var = 0\n",
    "for i in np.arange(percentage_variance.shape[0]):\n",
    "    if sum_var >= representation_percentage:\n",
    "        num_var = i\n",
    "        break;\n",
    "    \n",
    "    sum_var += percentage_variance[i]\n",
    "    \n",
    "num_var_select=num_var    \n",
    "print(\"Principal components number: \",num_var_select)\n",
    "print(\"Percent of variability captured: \",sum_var*100)\n",
    "print(\"Images in datasets\",datasetfull_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_per=np.cumsum(percentage_variance)\n",
    "for i in range(1,len(s)):\n",
    "    change=(cum_per[i]-cum_per[i-1])/cum_per[i-1]*100\n",
    "    if(change<.01):\n",
    "        num_var=i-1\n",
    "        print(\"First\",num_var, \"components with \",cum_per[num_var]*100,\"percent of variability captured and from which the contribution is less than 0.01%\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(cum_per*100)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Cumulative Summation of the Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EigenvectorsA=np.dot(datafull.T,u[:,0:num_var_select])\n",
    "NormEigenvectorsA = preprocessing.normalize(EigenvectorsA,axis=0, norm='l2')\n",
    "print(np.linalg.norm(NormEigenvectorsA[:,5],ord=None))#check normalizacion vectores propios de XT.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0.8\n",
    "step=0.06\n",
    "stop=1\n",
    "\n",
    "facespace(percentage_variance,datasetfull,datafull,mean_all_full,u,datasetfull_N,height,width,start,step,stop,dataset_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Principal components number: \",num_var_select)\n",
    "print(\"Percent of variability captured: \",sum_var*100)\n",
    "print(\"Images in datasets\",datasetfull_N)\n",
    "print(\"Omega matrix facespace\",np.dot(datafull,NormEigenvectorsA).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_image= np.random.randint(3059, high=datasetfull.shape[0], size=1)[0]\n",
    "Image=datafull[N_image]\n",
    "w=np.dot(Image,NormEigenvectorsA)\n",
    "Reconstructed=np.dot(w,NormEigenvectorsA.T)+mean_all_full.reshape(height*width)\n",
    "example_image = Reconstructed\n",
    "original_image = datasetfull[N_image]\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Original Image\")\n",
    "ax1.imshow(original_image, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"Reconstructed Image\")\n",
    "ax2.imshow(example_image.reshape(height,width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafullReconstructed=np.dot(np.dot(datafull,NormEigenvectorsA),NormEigenvectorsA.T)+mean_all_full.reshape(height*width)\n",
    "print(datafullReconstructed.shape)\n",
    "edistancefull = np.linalg.norm(np.subtract(datafullReconstructed, datasetfull.reshape(datasetfull_N, height*width)), ord=ordn, axis=1)\n",
    "print(edistancefull.shape)\n",
    "histbox(edistancefull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(edistancefull))\n",
    "percentil_93, percentil_94 = np.percentile(edistancefull, [93, 94])\n",
    "outliersindex=np.where(edistancefull > percentil_93)\n",
    "outliersfull=edistancefull[outliersindex]\n",
    "zsort=z[outliersindex]\n",
    "indexsortout=np.argsort(outliersfull)\n",
    "outliersfull=outliersfull[indexsortout]\n",
    "zsort=zsort[indexsortout]\n",
    "\n",
    "indexsort=np.argsort(edistancefull) #indice de imagenes distance de menor a mayor\n",
    "edistancesort=edistancefull[indexsort] #distancias de imagenes menor a mayor\n",
    "\n",
    "print('Outliers threshold method=',np.size(outliersfull))\n",
    "print('percentil_93=',percentil_93)\n",
    "#print('Q1= ',quartile_1, 'Q3= ',quartile_3)\n",
    "CVresult={'outliers distancefull':outliersfull,'z':zsort}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.sort_values('z', axis = 0, ascending = False, inplace = True, na_position ='first') \n",
    "df.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 2\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"z \"+str(z[indexsort[-(i+1)]]),fontsize=20)\n",
    "    plt.imshow(datasetfull[indexsort[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.ones(dataset_N)\n",
    "y_true=np.append(y_true,np.zeros(landscapes.shape[0]))\n",
    "y_pred=(edistancefull<=percentil_93)*1\n",
    "#y_pred=(z <= threshold)*1\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print('TP=', tp,'TN=',tn,'FP=',fp,'FN=', fn)\n",
    "print('accuracy= ', (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Heatmap\")\n",
    "prediction_data = {'y_Actual': y_true,'y_Predicted': y_pred}\n",
    "df = pd.DataFrame(prediction_data, columns=['y_Actual','y_Predicted'])\n",
    "confusionmatrix1 = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "ax=sns.heatmap(confusionmatrix1, annot=True,cmap='Blues', fmt='.0f');\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised image classification - K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Principal components number: \",num_var_select)\n",
    "print(\"Percent of variability captured: \",sum_var*100)\n",
    "print(\"Images in datasets\",datasetfull_N)\n",
    "print(\"Omega matrix facespace\",np.dot(datafull,NormEigenvectorsA).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omegaw=np.dot(datafull,NormEigenvectorsA)\n",
    "print(omegaw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(omegaw)\n",
    "wcentroids=kmeans.cluster_centers_\n",
    "wcentroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 3\n",
    "rows = 1\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"Class \"+str(i+1))\n",
    "    plt.imshow((np.dot(kmeans.cluster_centers_[i],NormEigenvectorsA.T)+mean_all_full.reshape(height*width)).reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label=kmeans.labels_\n",
    "wtotaldist=kmeans.transform(omegaw)\n",
    "wdistances = np.amin(wtotaldist, axis=1)\n",
    "\n",
    "print(wdistances.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclass=0\n",
    "print(\"Number images: \"+str(wdistances[y_label==kclass].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histbox(wdistances[y_label==kclass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVresult={'w distances':wdistances,'label':y_label}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.sort_values('w distances', axis = 0, ascending = True, inplace = True, na_position ='first')\n",
    "df2=df.loc[df[df.columns[1]]==kclass]\n",
    "df2.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low distances\n",
    "cols = 4\n",
    "rows = 1\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"Class1 low distance \"+ str(df2['w distances'][df2.index[i]]),fontsize=20)\n",
    "    plt.imshow(datasetfull[df2.index[i]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#High distances\n",
    "cols = 4\n",
    "rows = 1\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"Class1 high distance \"+ str(df2['w distances'][df2.index[-(i+1)]]),fontsize=20)\n",
    "    plt.imshow(datasetfull[df2.index[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclass=1\n",
    "print(\"Number images: \"+str(wdistances[y_label==kclass].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histbox(wdistances[y_label==kclass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVresult={'w distances':wdistances,'label':y_label}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.sort_values('w distances', axis = 0, ascending = True, inplace = True, na_position ='first')\n",
    "df2=df.loc[df[df.columns[1]]==kclass]\n",
    "df2.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low distances\n",
    "cols = 4\n",
    "rows = 1\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"Class2 low distance \"+ str(df2['w distances'][df2.index[i]]),fontsize=20)\n",
    "    plt.imshow(datasetfull[df2.index[i]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#High distances\n",
    "cols = 4\n",
    "rows = 1\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"Class2 high distance \"+ str(df2['w distances'][df2.index[-(i+1)]]),fontsize=20)\n",
    "    plt.imshow(datasetfull[df2.index[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclass=2\n",
    "print(\"Number images: \"+str(wdistances[y_label==kclass].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histbox(wdistances[y_label==kclass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVresult={'w distances':wdistances,'label':y_label}\n",
    "df = pd.DataFrame(CVresult)\n",
    "df.sort_values('w distances', axis = 0, ascending = True, inplace = True, na_position ='first')\n",
    "df2=df.loc[df[df.columns[1]]==kclass]\n",
    "df2.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#low distances\n",
    "cols = 4\n",
    "rows = 1\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"Class3 low distance \"+ str(df2['w distances'][df2.index[i]]),fontsize=20)\n",
    "    plt.imshow(datasetfull[df2.index[i]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#High distances\n",
    "cols = 4\n",
    "rows = 1\n",
    "plt.figure(figsize=(25,15))\n",
    "for i in np.arange(rows * cols):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.title(\"Class3 high distance \"+ str(df2['w distances'][df2.index[-(i+1)]]),fontsize=20)\n",
    "    plt.imshow(datasetfull[df2.index[-(i+1)]], plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.ones(faces94_male.shape[0])*2\n",
    "y_true=np.append(y_true,np.ones(faces94_female.shape[0]))\n",
    "y_true=np.append(y_true,np.ones(faces94_malestaff.shape[0])*2)\n",
    "y_true=np.append(y_true,np.zeros(landscapes.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_true, y_label).ravel()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Heatmap\")\n",
    "prediction_data = {'y_Actual': y_true,'y_Predicted': y_label}\n",
    "df = pd.DataFrame(prediction_data, columns=['y_Actual','y_Predicted'])\n",
    "confusionmatrix1 = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "ax=sns.heatmap(confusionmatrix1, annot=True,cmap='Blues', fmt='.0f');\n",
    "ax.xaxis.set_ticklabels(['landscape', 'female','male']); ax.yaxis.set_ticklabels(['landscape', 'female','male']);\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy= ', (cm[0]+cm[4]+cm[8])/np.sum(cm))\n",
    "print('accuracy= ', cm[0]/y_true[y_true==0].shape[0],cm[4]/y_true[y_true==1].shape[0],cm[8]/y_true[y_true==2].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeansk, NormEigenvectorsAk, X_train, X_test, y_predk= kmeansplit(datasetfull,y_label,datasetfull_N,height,width,representation_percentage,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number images Test: \"+str(y_predk.shape[0]))\n",
    "print(\"Number images class 1: \"+str(y_predk[y_predk==0].shape[0]))\n",
    "print(\"Number images class 2: \"+str(y_predk[y_predk==1].shape[0]))\n",
    "print(\"Number images class 3: \"+str(y_predk[y_predk==2].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_image= np.random.randint(0, high=X_test.shape[0], size=1)[0]\n",
    "print('Demo: predict new image as class '+ str(y_predk[N_image]+1))\n",
    "Image=X_test[N_image]#seleccionar imagen individual\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Image\")\n",
    "ax1.imshow(Image, plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"class \"+str(y_predk[N_image]+1))\n",
    "ax2.imshow((np.dot(kmeansk.cluster_centers_[y_predk[N_image]],NormEigenvectorsAk.T)+np.mean(X_train.reshape(X_train.shape[0], height*width), axis=0)).reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclass1=faces94_female\n",
    "dataset_N2, height, width = dataclass1.shape\n",
    "mean_class1 = np.mean(dataclass1.reshape(dataset_N2, height*width), axis=0)\n",
    "plt.imshow(mean_class1.reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omegaclass1=mean_class1 - np.mean(dataset.reshape(dataset_N, height*width), axis=0)\n",
    "wclass1=np.dot(omegaclass1,NormEigenvectorsA)#pesos w de cada Eigenface en subespacio generado\n",
    "Reconstructedc1=np.dot(wclass1,NormEigenvectorsA.T)+mean_all.reshape(height*width)#es mas claro w*vectores propios transpuestos\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.title(\"Female mean\")\n",
    "ax1.imshow(mean_class1.reshape(height, width), plt.cm.gray)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.title(\"Reconstructed Female mean\")\n",
    "ax2.imshow(Reconstructedc1.reshape(height, width), plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1=dataclass1.reshape(dataset_N2, height*width)-mean_all.reshape(height*width)\n",
    "wclass1total=np.dot(class1,NormEigenvectorsA)\n",
    "print(wclass1total.shape)\n",
    "print(wclass1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm=2\n",
    "edistanceclass1 = np.linalg.norm(np.subtract(wclass1total, wclass1), ord=Norm, axis=1)\n",
    "print(edistanceclass1.shape)\n",
    "print(wclass1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Histogram')\n",
    "plt.grid(True)\n",
    "plt.hist(edistanceclass1);\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Boxplot')\n",
    "plt.boxplot(edistanceclass1, 0, 'rs', 0);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartile_1, quartile_3 = np.percentile(edistanceclass1, [25, 75])\n",
    "\n",
    "\n",
    "image_index = np.random.randint(0, high=dataset_N, size=1)[0]\n",
    "Imagetest=dataset[image_index].reshape(height*width) - np.mean(dataset.reshape(dataset_N, height*width), axis=0)\n",
    "wtest=np.dot(Imagetest,NormEigenvectorsA)\n",
    "\n",
    "Norm=2\n",
    "test = np.linalg.norm(np.subtract(wtest, wclass1), ord=Norm, axis=0)\n",
    "\n",
    "if test>quartile_3:\n",
    "        print('no es mujer')\n",
    "else:\n",
    "        print('es mujer')\n",
    "print(quartile_3) \n",
    "print(test)    \n",
    "   \n",
    "plt.imshow(dataset[image_index], plt.cm.gray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm=2\n",
    "edistanceclass1t = np.linalg.norm(np.subtract(np.dot(data,NormEigenvectorsA), wclass1), ord=Norm, axis=1)\n",
    "print(edistanceclass1t.shape)\n",
    "print(wclass1.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Histogram')\n",
    "plt.grid(True)\n",
    "plt.hist(edistanceclass1t);\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Boxplot')\n",
    "plt.boxplot(edistanceclass1t, 0, 'rs', 0);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
